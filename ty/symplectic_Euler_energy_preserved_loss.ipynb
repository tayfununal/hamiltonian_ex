{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "symplectic_Euler_energy_preserved_loss.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMMvMzbsoBV2ALGfWINjeqh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tayfununal/hamiltonian_ex/blob/main/symplectic_Euler_energy_preserved_loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukhCiqlyL-_O"
      },
      "outputs": [],
      "source": [
        "#simplektik euler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "plt.style.use('seaborn-poster')\n",
        "\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def grand_truth_plot(h = 0.3):\n",
        "  t = np.arange(0,2*np.pi,h)\n",
        "  q = np.sin(t)\n",
        "  p = np.cos(t)\n",
        "  plt.scatter(q,p)\n",
        "\n",
        "def pred_plot(q, p):\n",
        "  plt.plot(q[:, ], p[:,], c = \"red\")\n",
        "  plt.xlabel('q', fontsize=17,fontweight=\"bold\",fontname=\"Times New Roman\")\n",
        "  plt.ylabel('p', fontsize=17,fontweight=\"bold\",fontname=\"Times New Roman\")\n",
        "  plt.title(\"Phase Diagram\", fontsize=17,fontweight=\"bold\",fontname=\"Times New Roman\")"
      ],
      "metadata": {
        "id": "hHTrtn4dMgvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hamiltonian Equation\n",
        "\n",
        "def T(p):\n",
        "  return (p**2)/2\n",
        "\n",
        "def V(q):\n",
        "  return (q**2)/2\n",
        "\n",
        "def H(q,p):\n",
        "  return T(p) + V(q)"
      ],
      "metadata": {
        "id": "h9AjdhIXMBkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dV(q_0=tf.constant(1.0)):\n",
        "  q_0 = tf.constant(q_0)\n",
        "  with tf.GradientTape() as g:\n",
        "    g.watch(q_0)\n",
        "    y = V(q_0)\n",
        "  return g.gradient(y, q_0)\n",
        "\n",
        "def dT(p_0=tf.constant(1.0)):\n",
        "  p_0 = tf.constant(p_0)\n",
        "  with tf.GradientTape() as g:\n",
        "    g.watch(p_0)\n",
        "    y = T(p_0)\n",
        "  return g.gradient(y, p_0)"
      ],
      "metadata": {
        "id": "VR2yUkyKMDbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def symplectic_euler(dT=dT, dV=dV ,h=0.5, initial_point= [0., 1.]):\n",
        "\n",
        "  t = np.arange(0, 2*np.pi, h)\n",
        "\n",
        "  q = np.zeros(t.shape[0])\n",
        "  p = np.zeros(t.shape[0])\n",
        "\n",
        "  q[0] = initial_point[0]\n",
        "  p[0] = initial_point[1]\n",
        "  \n",
        "  for i in range(0, t.shape[0]-1):\n",
        "\n",
        "    q[i + 1] = q[i] + h * dT(p[i])\n",
        "    p[i + 1] = p[i] - h * dV(q[i+1])\n",
        "  \n",
        "  z = np.concatenate((q.reshape(-1,1), p.reshape(-1,1)) , axis=1)\n",
        "  return z, t"
      ],
      "metadata": {
        "id": "sMO3lE8JMKat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z, t = symplectic_euler()\n",
        "print(\"shape of q :\", z[:,0].shape ,\"\\nshape of p:\", z[:,1].shape, \"\\nsize of t:\", len(t))"
      ],
      "metadata": {
        "id": "P1T1cpyaMKde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (4, 4))\n",
        "\n",
        "# Simplectic solution plot\n",
        "pred_plot(q=z[:,0], p=z[:,1])\n",
        "\n",
        "# Grand truth solution plot\n",
        "grand_truth_plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YvBc6irYMKiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def NN(input =1, output=2, hidden_layer=2, neuron=32, activation=\"relu\", energy_loss=None):\n",
        "  # Neural network with MSE loss\n",
        "  np.random.seed(1)\n",
        "  tf.random.set_seed(1)\n",
        "\n",
        "  inp = Input(shape=(input,), name= \"Input_Layer\")\n",
        "  for i in range(0,hidden_layer):\n",
        "    if i == 0:\n",
        "      x = Dense(neuron, activation=activation, name=\"Hidden_Layer_{}\".format(i+1))(inp)\n",
        "    else:\n",
        "      x = Dense(neuron, activation=activation, name=\"Hidden_Layer_{}\".format(i+1))(x)\n",
        "  x = Dense(output, name=\"Ourput_Layer\")(x)\n",
        "  \n",
        "\n",
        "  out = tf.constant([[0.,1.]], dtype=tf.float32) + (1-tf.math.exp(-inp**2)) * x\n",
        "\n",
        "  return Model(inputs=inp, outputs=out)"
      ],
      "metadata": {
        "id": "jedeCslnMKk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,input, target, learning_rate=0.0003, loss=\"mse\", batch_size=10000, epochs=2000):\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "  model.compile(optimizer=opt, loss=loss)\n",
        "  model.fit(x=input, y=target, epochs=epochs, batch_size=batch_size)\n",
        "  return model"
      ],
      "metadata": {
        "id": "_mxluZA6M2_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NN(input= 1,output=2, hidden_layer=20, neuron=32, activation=tf.math.sin)\n",
        "model_train = train(model=model, input=t, target=z, learning_rate=0.0003, loss=\"mse\", batch_size=10000, epochs=2000)"
      ],
      "metadata": {
        "id": "C0oxRXv8MKnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_t = np.arange(0, 2*np.pi, 0.001)\n",
        "prediction = model_train(test_t)\n",
        "\n",
        "q = prediction[:,0]\n",
        "p = prediction[:,1]\n",
        "\n",
        "plt.figure(figsize = (4, 4))\n",
        "\n",
        "# NN with mse solition \n",
        "pred_plot(q, p )\n",
        "\n",
        "# Grand truth solution plot\n",
        "grand_truth_plot()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zAACnW14MKzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Energy loss function\n",
        "def custom_loss(y_true, y_pred):\n",
        "  return tf.keras.losses.MSE(0.5, H(y_pred[None,:,0], y_pred[None, :,1])) + 0.001 * tf.keras.losses.MSE(y_true,y_pred)"
      ],
      "metadata": {
        "id": "UlYQUsLzMK1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "energy_model = NN(input= 1,output=2, hidden_layer=20, neuron=32, activation=tf.math.sin, energy_loss=custom_loss)"
      ],
      "metadata": {
        "id": "N8bpnLCVMK6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parametreleri atama ve veri arttÄ±rma\n",
        "energy_model.set_weights(model_train.get_weights())\n",
        "\n",
        "t_created = np.arange(0, 2*np.pi, 0.001)\n",
        "target_created = model_train(t_created)"
      ],
      "metadata": {
        "id": "09XtkQmlMK88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "energy_model_train = train(model=energy_model, input=t_created, target=target_created, learning_rate=0.0003, loss=custom_loss, batch_size=10000, epochs=2000)"
      ],
      "metadata": {
        "id": "qeSAJ6cTO3Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_t = np.arange(0, 2*np.pi, 0.001)\n",
        "prediction_energy = energy_model_train(test_t)\n",
        "\n",
        "q_energy = prediction_energy[:,0]\n",
        "p_energy = prediction_energy[:,1]\n",
        "\n",
        "plt.figure(figsize = (4, 4))\n",
        "\n",
        "# NN with mse solition \n",
        "pred_plot(q_energy, p_energy )\n",
        "\n",
        "# Grand truth solution plot\n",
        "grand_truth_plot()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j-UKsCL8O3sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "\n",
        "plt.scatter(t, [0.5 for i in range(t.shape[0])], label=\"Grand truth\")\n",
        "plt.plot(t , H(z[:,0], z[:,1]), label=\"Symplectic Euler\")\n",
        "plt.plot(test_t, H(model_train(test_t)[:,0], model_train(test_t)[:,0]), label=\"NN with MSE loss\")\n",
        "plt.plot(test_t, H(energy_model_train(test_t)[:,0], energy_model_train(test_t)[:,1]), label=\"NN with Energy Preserved loss\")\n",
        "\n",
        "plt.title(\"Energy of The Hamiltonian System\", fontsize=17, fontweight=\"bold\", fontname=\"Times New Roman\")\n",
        "plt.xlabel(\"t\", fontsize=17, fontweight=\"bold\", fontname=\"Times New Roman\")\n",
        "plt.ylabel(\"Energy\", fontsize=17, fontweight=\"bold\", fontname=\"Times New Roman\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "esm2LhBXO3u_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grand_truth = np.concatenate((np.sin(t).reshape(-1,1), (np.cos(t).reshape(-1,1))), axis=1)"
      ],
      "metadata": {
        "id": "fD3Hli9HQe9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Symplectic\n",
        "plt.figure(figsize=(24,8))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.plot(t, grand_truth[:,0] - z[:,0], c = 'r', label=\"Error of Symplectic Euler\")\n",
        "plt.plot(t, grand_truth[:,0] - model_train(t)[:,0], c= 'g', label=\"Error of NN with MSE Loss\")\n",
        "plt.plot(t, grand_truth[:,0] - energy_model_train(t)[:,0] , c='b', label=\"Error of NN with Energy Preserved Loss\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(t, grand_truth[:,1] - z[:,1], c = 'r', label=\"Error of Symplectic Euler\")\n",
        "plt.plot(t, grand_truth[:,1] - model_train(t)[:,1], c= 'g', label=\"Error of NN with MSE Loss\")\n",
        "plt.plot(t, grand_truth[:,1] - energy_model_train(t)[:,1] , c='b', label=\"Error of NN with Energy Preserved Loss\")\n",
        "plt.legend(loc=\"upper right\")"
      ],
      "metadata": {
        "id": "aq_cwcW4Qlw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "m6Sy9JKRRNtD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
